{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import numpy\n",
    "from scipy import signal\n",
    "from numpy.lib.stride_tricks import as_strided as ast\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import albumentations as A\n",
    "\n",
    "def fspecial_gauss(size, sigma):\n",
    "    \"\"\"\n",
    "        Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g/g.sum()\n",
    "\n",
    "def ssim(img1, img2, cs_map=False):\n",
    "    \"\"\"Return the Structural Similarity Map corresponding to input images img1 \n",
    "    and img2 (images are assumed to be uint8)\n",
    "    \n",
    "    This function attempts to mimic precisely the functionality of ssim.m a \n",
    "    MATLAB provided by the author's of SSIM\n",
    "    https://ece.uwaterloo.ca/~z70wang/research/ssim/ssim_index.m\n",
    "    \"\"\"\n",
    "    #range [0,1]\n",
    "    img1 = img1.astype(numpy.float64).clip(0, 8000.) / 8000.\n",
    "    img2 = img2.astype(numpy.float64).clip(0, 8000.) / 8000.\n",
    "    size = 11\n",
    "    sigma = 1.5\n",
    "    window = fspecial_gauss(size, sigma)\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    L = 1. #bitdepth of image\n",
    "    C1 = (K1*L)**2\n",
    "    C2 = (K2*L)**2\n",
    "    mu1 = signal.fftconvolve(window, img1, mode='valid')\n",
    "    mu2 = signal.fftconvolve(window, img2, mode='valid')\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "    sigma1_sq = signal.fftconvolve(window, img1*img1, mode='valid') - mu1_sq\n",
    "    sigma2_sq = signal.fftconvolve(window, img2*img2, mode='valid') - mu2_sq\n",
    "    sigma12 = signal.fftconvolve(window, img1*img2, mode='valid') - mu1_mu2\n",
    "    if cs_map:\n",
    "        return (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2)), \n",
    "                (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
    "    else:\n",
    "        return ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2))\n",
    "    \n",
    "def norm_shape(shape):\n",
    "    '''\n",
    "    Normalize numpy array shapes so they're always expressed as a tuple, \n",
    "    even for one-dimensional shapes.\n",
    "\n",
    "    Parameters\n",
    "        shape - an int, or a tuple of ints\n",
    "\n",
    "    Returns\n",
    "        a shape tuple\n",
    "    '''\n",
    "    try:\n",
    "        i = int(shape)\n",
    "        return (i,)\n",
    "    except TypeError:\n",
    "        # shape was not a number\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        t = tuple(shape)\n",
    "        return t\n",
    "    except TypeError:\n",
    "        # shape was not iterable\n",
    "        pass\n",
    "\n",
    "    raise TypeError('shape must be an int, or a tuple of ints')\n",
    "\n",
    "\n",
    "def sliding_window(a,ws,ss = None,flatten = False):\n",
    "    '''\n",
    "    Return a sliding window over a in any number of dimensions\n",
    "\n",
    "    Parameters:\n",
    "        a  - an n-dimensional numpy array\n",
    "        ws - an int (a is 1D) or tuple (a is 2D or greater) representing the size \n",
    "             of each dimension of the window\n",
    "        ss - an int (a is 1D) or tuple (a is 2D or greater) representing the \n",
    "             amount to slide the window in each dimension. If not specified, it\n",
    "             defaults to ws.\n",
    "        flatten - if True, all slices are flattened, otherwise, there is an \n",
    "                  extra dimension for each dimension of the input.\n",
    "\n",
    "    Returns\n",
    "        an array containing each n-dimensional window from a\n",
    "\n",
    "    from http://www.johnvinyard.com/blog/?p=268\n",
    "    '''\n",
    "\n",
    "    if None is ss:\n",
    "        # ss was not provided. the windows will not overlap in any direction.\n",
    "        ss = ws\n",
    "    ws = norm_shape(ws)\n",
    "    ss = norm_shape(ss)\n",
    "\n",
    "    # convert ws, ss, and a.shape to numpy arrays so that we can do math in every \n",
    "    # dimension at once.\n",
    "    ws = np.array(ws)\n",
    "    ss = np.array(ss)\n",
    "    shape = np.array(a.shape)\n",
    "\n",
    "\n",
    "    # ensure that ws, ss, and a.shape all have the same number of dimensions\n",
    "    ls = [len(shape),len(ws),len(ss)]\n",
    "    if 1 != len(set(ls)):\n",
    "        raise ValueError(\\\n",
    "        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n",
    "\n",
    "    # ensure that ws is smaller than a in every dimension\n",
    "    if np.any(ws > shape):\n",
    "        raise ValueError('ws cannot be larger than a in any dimension. a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n",
    "\n",
    "    # how many slices will there be in each dimension?\n",
    "    newshape = norm_shape(((shape - ws) // ss) + 1)\n",
    "    # the shape of the strided array will be the number of slices in each dimension\n",
    "    # plus the shape of the window (tuple addition)\n",
    "    newshape += norm_shape(ws)\n",
    "    # the strides tuple will be the array's strides multiplied by step size, plus\n",
    "    # the array's strides (tuple addition)\n",
    "    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n",
    "    strided = ast(a,shape = newshape,strides = newstrides)\n",
    "    if not flatten:\n",
    "        return strided\n",
    "\n",
    "    # Collapse strided so that it has one more dimension than the window.  I.e.,\n",
    "    # the new array is a flat list of slices.\n",
    "    meat = len(ws) if ws.shape else 0\n",
    "    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n",
    "    dim = firstdim + (newshape[-meat:])\n",
    "    # remove any dimensions with size 1\n",
    "    dim = filter(lambda i : i != 1,dim)\n",
    "    return strided.reshape(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 1296, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "a = imageio.imread('/all_data/Scannet_all_data/img/scene0000_00_0.jpg')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_patches(fname):\n",
    "    #resize\n",
    "    resize = A.Compose([A.Resize(height=960, width=1280, interpolation=4, p=1)], p=1)\n",
    "    fname_base, ext = os.path.splitext(fname)\n",
    "    img = imageio.imread(os.path.join(sourse_path, 'img', fname_base + '.jpg'))\n",
    "    img = resize(image=img)['image']\n",
    "    depth_lq = imageio.imread(os.path.join(sourse_path, 'raw', fname))\n",
    "    depth_sr = imageio.imread(os.path.join(sourse_path, 'render', fname))\n",
    "    H, W = depth_lq.shape\n",
    "\n",
    "    ssim_mtrx = ssim(depth_lq, depth_sr[0::2, 0::2])\n",
    "    H_p, W_p = ssim_mtrx.shape\n",
    "    assert ((H - H_p) % 2 == 0) and ((H - H_p) // 2 == (W - W_p) // 2 ), 'check how fftconvolve produce valid mode'\n",
    "    pad = (H - H_p) // 2\n",
    "    #valid mode don't return values influenced by zero-padding\n",
    "    depth_sr = depth_sr[2*pad:-2*pad, 2*pad:-2*pad]\n",
    "    depth_lq = depth_lq[pad:-pad, pad:-pad]\n",
    "    img = img[2*pad:-2*pad, 2*pad:-2*pad, :]\n",
    "    \n",
    "    ssim_patch = sliding_window(ssim_mtrx, (320, 320), (64, 64))\n",
    "    ssim_idx = ssim_patch.mean(axis=(2,3)) > 0.8\n",
    "    n = ssim_idx.sum()\n",
    "\n",
    "    if n > 0:\n",
    "        \n",
    "        depth_sr_patch = sliding_window(depth_sr, (640,640), (128,128))\n",
    "\n",
    "        hole_v = 5\n",
    "        hole_idx = (depth_sr_patch > hole_v).mean(axis=(2,3)) > 0.9\n",
    "        final_idx = hole_idx *  ssim_idx\n",
    "        n_good = final_idx.sum()\n",
    "        patch_idx = np.argwhere(final_idx)\n",
    "        if n_good == 0:\n",
    "            return\n",
    "        else:\n",
    "            depth_lq_patch = sliding_window(depth_lq, (320, 320), (64, 64))\n",
    "            img_patch = sliding_window(img, (640,640,3), (128, 128, 1) )\n",
    "            \n",
    "            depth_gt_good = depth_sr_patch[final_idx][:, 0::2, 0::2]\n",
    "            depth_lq_good = depth_lq_patch[final_idx]\n",
    "            img_good = img_patch[final_idx]\n",
    "            depth_sr_good = depth_sr_patch[final_idx]\n",
    "            for i in range(n_good):\n",
    "                imageio.imsave(\"/all_data/hdd/un_depth/Scannet_filtered/img/{}_{}_{}{}\".format(fname_base, patch_idx[i,0], patch_idx[i,1], \".jpg\"), img_good[i,0])\n",
    "                imageio.imsave(\"/all_data/hdd/un_depth/Scannet_filtered/raw/{}_{}_{}{}\".format(fname_base, patch_idx[i,0], patch_idx[i,1], ext), depth_lq_good[i])\n",
    "                imageio.imsave(\"/all_data/hdd/un_depth/Scannet_filtered/render/{}_{}_{}{}\".format(fname_base, patch_idx[i,0], patch_idx[i,1], ext), depth_gt_good[i])\n",
    "                imageio.imsave(\"/all_data/hdd/un_depth/Scannet_filtered/depth_sr/{}_{}_{}{}\".format(fname_base, patch_idx[i,0], patch_idx[i,1], ext), depth_sr_good[i])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourse_path = '/all_data/hdd/un_depth/Scannet_all_data/' \n",
    "fnames = sorted(os.listdir(os.path.join(sourse_path, 'raw')))\n",
    "n_processes = 15\n",
    "with Pool(n_processes) as p:   \n",
    "    res = list(tqdm.tqdm(p.imap(func=calc_ssim, iterable=fnames), total=len(fnames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and count scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/all_data/hdd/un_depth/Scannet_filtered/'\n",
    "test_path = '/all_data/hdd/un_depth/Scannet_filtered/test/'\n",
    "val_path = '/all_data/hdd/un_depth/Scannet_filtered/val/'\n",
    "img = sorted(os.listdir(os.path.join(path,'img')))\n",
    "raw = sorted(os.listdir(os.path.join(path,'raw')))\n",
    "render = sorted(os.listdir(os.path.join(path,'render')))\n",
    "depth_sr = sorted(os.listdir(os.path.join(path,'depth_sr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img) == len(render) == len(raw) == len(depth_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126475"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img)):\n",
    "    assert img[i].split('.')[0] == raw[i].split('.')[0] == render[i].split('.')[0] == depth_sr[i].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for i in range(len(img)):\n",
    "    count[img[i].split(\"_\")[0]] = count.get(img[i].split(\"_\")[0], 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same_values = []\n",
    "# for f in tqdm.tqdm(raw):\n",
    "#     if np.unique(imageio.imread(os.path.join(path, 'raw', f))).shape[0] < 2 or np.unique(imageio.imread(os.path.join(path, 'render', f))).shape[0] < 2:\n",
    "#         same_values.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 0\n",
    "test_scene = []\n",
    "while n_test < 10000:\n",
    "    scene, n = random.choice(list(count.items()))\n",
    "    n_test += n\n",
    "    test_scene.append(scene)\n",
    "    del count[scene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126475/126475 [00:01<00:00, 108864.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm.tqdm(img):\n",
    "    if f.split(\"_\")[0] in test_scene:\n",
    "        name = f.split('.')[0]\n",
    "        os.rename(os.path.join(path, 'img', name+'.jpg'), os.path.join(test_path, 'img', name+'.jpg'))\n",
    "        os.rename(os.path.join(path, 'raw', name+'.png'), os.path.join(test_path, 'raw', name+'.png'))\n",
    "        os.rename(os.path.join(path, 'render', name+'.png'), os.path.join(test_path, 'render', name+'.png'))\n",
    "        os.rename(os.path.join(path, 'depth_sr', name+'.png'), os.path.join(test_path, 'depth_sr', name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = 0\n",
    "val_scene = []\n",
    "while n_val < 5000:\n",
    "    scene, n = random.choice(list(count.items()))\n",
    "    n_val += n\n",
    "    val_scene.append(scene)\n",
    "    del count[scene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116095/116095 [00:00<00:00, 177832.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm.tqdm(img):\n",
    "    if f.split(\"_\")[0] in val_scene:\n",
    "        name = f.split('.')[0]\n",
    "        os.rename(os.path.join(path, 'img', name+'.jpg'), os.path.join(val_path, 'img', name+'.jpg'))\n",
    "        os.rename(os.path.join(path, 'raw', name+'.png'), os.path.join(val_path, 'raw', name+'.png'))\n",
    "        os.rename(os.path.join(path, 'render', name+'.png'), os.path.join(val_path, 'render', name+'.png'))\n",
    "        os.rename(os.path.join(path, 'depth_sr', name+'.png'), os.path.join(val_path, 'depth_sr', name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene = np.array(test_scene)\n",
    "val_scene = np.array(val_scene)\n",
    "np.save('./test_scene', test_scene)\n",
    "np.save('./val_scene', val_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sorted(os.listdir(os.path.join(path,'img')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for i in range(len(img)):\n",
    "    count[img[i].split(\"_\")[0]] = count.get(img[i].split(\"_\")[0], 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trainA = 0\n",
    "trainA_scene = []\n",
    "while n_trainA < len(img) // 2:\n",
    "    scene, n = random.choice(list(count.items()))\n",
    "    n_trainA += n\n",
    "    trainA_scene.append(scene)\n",
    "    del count[scene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainA_path = '/all_data/hdd/un_depth/Scannet_filtered/trainA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110749/110749 [00:06<00:00, 18190.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm.tqdm(img):\n",
    "    if f.split(\"_\")[0] in trainA_scene:\n",
    "        name = f.split('.')[0]\n",
    "        os.rename(os.path.join(path, 'img', name+'.jpg'), os.path.join(trainA_path, 'img', name+'.jpg'))\n",
    "        os.rename(os.path.join(path, 'raw', name+'.png'), os.path.join(trainA_path, 'raw', name+'.png'))\n",
    "        os.rename(os.path.join(path, 'render', name+'.png'), os.path.join(trainA_path, 'render', name+'.png'))\n",
    "        os.rename(os.path.join(path, 'depth_sr', name+'.png'), os.path.join(trainA_path, 'depth_sr', name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56227"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trainA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
